(window.webpackJsonp=window.webpackJsonp||[]).push([[123],{561:function(s,n,a){"use strict";a.r(n);var e=a(30),t=Object(e.a)({},(function(){var s=this,n=s.$createElement,a=s._self._c||n;return a("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[a("p",[s._v("今天我们来爬取专供初学者练习爬虫的网站 "),a("a",{attrs:{href:"http://books.toscrape.com/",target:"_blank",rel:"noopener noreferrer"}},[s._v("http://books.toscrape.com/"),a("OutboundLink")],1),s._v("\n这是一个图书网站，默认有50页，每页会展示20本书，我们要一次性把所有图书的标题和价格全部抓取下来。")]),s._v(" "),a("blockquote",[a("p",[a("img",{attrs:{src:"https://hexo-blog.pek3b.qingstor.com/upload_images/71414-a9e30e5c213f396a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240",alt:"image.png"}})])]),s._v(" "),a("p",[s._v("过程其实非常简单")]),s._v(" "),a("ol",[a("li",[s._v("新建项目 "),a("code",[s._v("scrapy startproject book")])]),s._v(" "),a("li",[a("code",[s._v("cd book; tree # 查看下项目结构")])]),s._v(" "),a("li",[s._v("spiders 目录下新建文件 "),a("code",[s._v("book_spider.py")]),s._v(" 或者使用命令\n"),a("code",[s._v("scrapy genspider books books.toscrape.com")]),s._v(" 会生成 books.py文件")])]),s._v(" "),a("div",{staticClass:"language- line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[s._v("# -*- coding: utf-8 -*-\nimport scrapy\n\n\nclass BooksSpider(scrapy.Spider):\n    name = 'books'\n    allowed_domains = ['books.toscrape.com']\n    start_urls = ['http://books.toscrape.com/']\n\n    def parse(self, response):\n        pass\n\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br")])]),a("ol",{attrs:{start:"4"}},[a("li",[s._v("分析 html 结构，先通过chrome的开发者工具的审查元素功能\n结合命令行 "),a("code",[s._v('scrapy shell "http://books.toscrape.com/"')])])]),s._v(" "),a("p",[s._v("更新 book_spider.py 为如下，内容非常简单")]),s._v(" "),a("div",{staticClass:"language- line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[s._v("import scrapy\n\n\nclass BooksSpider(scrapy.Spider):\n    name = \"books\"\n    start_urls = [\n        'http://books.toscrape.com/',\n    ]\n\n    def parse(self, response):\n        for book in response.css('article.product_pod'):\n            # 选择器可以通过命令行工具就行调试\n            yield {\n                # xpath 语法 @ATTR 为选中为名ATTR的属性节点\n                'name': book.xpath('h3/a/@title').get(),\n                'price': book.css('p.price_color::text').get(),\n            }\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br")])]),a("ol",{attrs:{start:"5"}},[a("li",[s._v("测试输出结果 "),a("code",[s._v("scrapy crawl books -o book.jl")])])]),s._v(" "),a("blockquote",[a("p",[s._v("jl 是 json line格式")])]),s._v(" "),a("ol",{attrs:{start:"6"}},[a("li",[s._v("为了完整抓取，来处理分页")])]),s._v(" "),a("div",{staticClass:"language- line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[s._v("class BooksSpider(scrapy.Spider):\n    # 爬取命令 scrapy crawl books\n    name = \"books\"\n\n    start_urls = [\n        'http://books.toscrape.com/',\n    ]\n\n    def parse(self, response):\n        for book in response.css('article.product_pod'):\n            yield {\n                'name': book.xpath('h3/a/@title').get(),\n                'price': book.css('p.price_color::text').get(),\n            }\n\n        # 检查分页\n        # 提取下一页的链接\n        next_url = response.css('ul.pager li.next a::attr(href)').extract_first()\n        if next_url:\n            next_url = response.urljoin(next_url)\n            # 构造新的 Request 对象\n            yield scrapy.Request(next_url, callback=self.parse)\n\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br"),a("span",{staticClass:"line-number"},[s._v("18")]),a("br"),a("span",{staticClass:"line-number"},[s._v("19")]),a("br"),a("span",{staticClass:"line-number"},[s._v("20")]),a("br"),a("span",{staticClass:"line-number"},[s._v("21")]),a("br"),a("span",{staticClass:"line-number"},[s._v("22")]),a("br"),a("span",{staticClass:"line-number"},[s._v("23")]),a("br")])]),a("p",[s._v("解释\nurljoin 是 response 对象提供的方法，传入相对地址生成绝对地址，然后再生成新的Request对象\nScrapy 本身不难，重点还是Python的基础")])])}),[],!1,null,null,null);n.default=t.exports}}]);